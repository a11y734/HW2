# ============================
# ğŸš— Car Price Prediction Project
# Dataset: hellbuoy/car-price-prediction
# Web App Deployment with Streamlit
# ============================

import pandas as pd
import numpy as np
from pathlib import Path
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
from sklearn.metrics import r2_score, mean_squared_error
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm

# è§£æ±º matplotlib ä¸­æ–‡é¡¯ç¤ºå•é¡Œ
plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False  # è§£æ±ºè² è™Ÿé¡¯ç¤ºå•é¡Œ


@st.cache_data
def load_data():
    """
    è¼‰å…¥ä¸¦å¿«å–è³‡æ–™ï¼ŒåŸ·è¡ŒåŸºæœ¬å‰è™•ç†ã€‚
    """
    # å»ºç«‹ç›¸å°æ–¼ç›®å‰ .py æª”æ¡ˆçš„æª”æ¡ˆè·¯å¾‘
    script_dir = Path(__file__).parent
    data_file = script_dir / "CarPrice_Assignment.csv"
    df = pd.read_csv(data_file)
    
    # åˆªé™¤æ˜é¡¯ä¸å¿…è¦æ¬„ä½
    df_processed = df.drop(["car_ID", "CarName"], axis=1)
    
    # è™•ç†é¡åˆ¥è®Šæ•¸
    categorical_cols = df_processed.select_dtypes(include='object').columns
    df_processed = pd.get_dummies(df_processed, columns=categorical_cols, drop_first=True, dtype=int)
    
    return df, df_processed

@st.cache_resource
def train_model(df_processed):
    """
    ä½¿ç”¨ RFE é¸æ“‡ç‰¹å¾µä¸¦è¨“ç·´ç·šæ€§è¿´æ­¸æ¨¡å‹ã€‚
    """
    X = df_processed.drop("price", axis=1)
    y = df_processed["price"]

    # åˆ†å‰²è¨“ç·´èˆ‡æ¸¬è©¦é›† (é›–ç„¶æ­¤è™•ç”¨å…¨éƒ¨è³‡æ–™è¨“ç·´ä»¥ç²å¾—æ›´ç©©å®šçš„æ¨¡å‹ï¼Œä½†ä¿ç•™åˆ†å‰²é‚è¼¯ä»¥ä¾›åƒè€ƒ)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # ç‰¹å¾µé¸æ“‡ (RFE)
    lr = LinearRegression()
    # é¸æ“‡15å€‹ç‰¹å¾µä»¥åŒ…å«æ›´å¤šä½¿ç”¨è€…å¯èª¿æ•´çš„é¸é …
    rfe = RFE(lr, n_features_to_select=15)
    rfe.fit(X_train, y_train)

    selected_features = X_train.columns[rfe.support_]

    # ä½¿ç”¨é¸å‡ºçš„ç‰¹å¾µè¨“ç·´æœ€çµ‚æ¨¡å‹
    final_model = LinearRegression()
    final_model.fit(X_train[selected_features], y_train)
    
    # è©•ä¼°æ¨¡å‹ä»¥ä¾›é¡¯ç¤º
    y_pred = final_model.predict(X_test[selected_features])
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    # å»ºç«‹ç‰¹å¾µé‡è¦æ€§ DataFrame
    importance_df = pd.DataFrame({'feature': selected_features, 'importance': np.abs(final_model.coef_)}).sort_values('importance', ascending=False)
    
    return final_model, selected_features, X_train, y_train, (r2, rmse), importance_df, (X_test, y_test)

# ==============================
# Streamlit App UI
# ==============================

st.set_page_config(page_title="ğŸš— è»Šåƒ¹é æ¸¬å™¨", layout="wide")
st.title("Car Price Prediction Dataset")
st.write("""
æœ¬å°ˆæ¡ˆä½¿ç”¨ Kaggle ä¸Šçš„æ±½è»Šåƒ¹æ ¼è³‡æ–™é›†ï¼Œé€éå¤šå…ƒç·šæ€§è¿´æ­¸æ¨¡å‹é€²è¡Œåˆ†æã€‚
æˆ‘å€‘åˆ©ç”¨éæ­¸ç‰¹å¾µæ¶ˆé™¤ï¼ˆRFEï¼‰æŠ€è¡“è‡ªå‹•ç¯©é¸å‡ºå½±éŸ¿è»Šåƒ¹çš„é—œéµç‰¹å¾µï¼Œä¸¦å»ºç«‹æ­¤äº’å‹•å¼å„€è¡¨æ¿ã€‚
é æœŸæ•ˆç›Šæ˜¯è®“ä½¿ç”¨è€…èƒ½é€éèª¿æ•´åƒæ•¸ç›´è§€åœ°äº†è§£å„é …ç‰¹å¾µå°è»Šåƒ¹çš„å½±éŸ¿ï¼Œä¸¦ç²å¾—ä¸€å€‹åˆç†çš„åƒ¹æ ¼é ä¼°ã€‚
""")

# è¼‰å…¥è³‡æ–™èˆ‡è¨“ç·´æ¨¡å‹
df_raw, df_processed = load_data()
model, selected_features, X_train, y_train, metrics, importance_df, test_data = train_model(df_processed)

def user_input_features(importance_df, container):
    """
    æ ¹æ“šç‰¹å¾µé‡è¦æ€§æ’åºï¼Œå»ºç«‹ä½¿ç”¨è€…è¼¸å…¥ä»‹é¢ã€‚
    container: The Streamlit container to draw the widgets in (e.g., st or st.sidebar)
    """
    inputs = {}
    # å»ºç«‹ä¸€å€‹ widget å‡½æ•¸çš„å°æ‡‰å­—å…¸
    widget_map = {
        'enginesize': lambda: container.slider('å¼•æ“å¤§å° (enginesize)', int(df_raw['enginesize'].min()), int(df_raw['enginesize'].max()), int(df_raw['enginesize'].mean())),
        'curbweight': lambda: container.slider('è»Šé‡ (curbweight)', int(df_raw['curbweight'].min()), int(df_raw['curbweight'].max()), int(df_raw['curbweight'].mean())),
        'horsepower': lambda: container.slider('é¦¬åŠ› (horsepower)', int(df_raw['horsepower'].min()), int(df_raw['horsepower'].max()), int(df_raw['horsepower'].mean())),
        'carwidth': lambda: container.slider('è»Šå¯¬ (carwidth)', float(df_raw['carwidth'].min()), float(df_raw['carwidth'].max()), float(df_raw['carwidth'].mean())),
        'carlength': lambda: container.slider('è»Šé•· (carlength)', float(df_raw['carlength'].min()), float(df_raw['carlength'].max()), float(df_raw['carlength'].mean())),
        'wheelbase': lambda: container.slider('è»¸è· (wheelbase)', float(df_raw['wheelbase'].min()), float(df_raw['wheelbase'].max()), float(df_raw['wheelbase'].mean())),
        'citympg': lambda: container.slider('åŸå¸‚æ²¹è€— (citympg)', int(df_raw['citympg'].min()), int(df_raw['citympg'].max()), int(df_raw['citympg'].mean())),
        'highwaympg': lambda: container.slider('é«˜é€Ÿæ²¹è€— (highwaympg)', int(df_raw['highwaympg'].min()), int(df_raw['highwaympg'].max()), int(df_raw['highwaympg'].mean())),
        'boreratio': lambda: container.slider('ç¼¸å¾‘æ¯” (boreratio)', float(df_raw['boreratio'].min()), float(df_raw['boreratio'].max()), float(df_raw['boreratio'].mean())),
        'aspiration': lambda: container.selectbox('é€²æ°£æ–¹å¼ (aspiration)', df_raw['aspiration'].unique()),
        'enginelocation': lambda: container.selectbox('å¼•æ“ä½ç½® (enginelocation)', df_raw['enginelocation'].unique()),
        'enginetype': lambda: container.selectbox('å¼•æ“é¡å‹ (enginetype)', df_raw['enginetype'].unique()),
        'carbody': lambda: container.selectbox('è»Šé«” (carbody)', df_raw['carbody'].unique()),
        'cylindernumber': lambda: container.selectbox('æ±½ç¼¸æ•¸ (cylindernumber)', df_raw['cylindernumber'].unique()),
    }
    
    # æ ¹æ“šé‡è¦æ€§æ’åºä¾†å‹•æ…‹ç”Ÿæˆ UI
    for feature_name in importance_df['feature']:
        # è™•ç† one-hot ç·¨ç¢¼çš„ç‰¹å¾µï¼Œæ‰¾åˆ°åŸå§‹çš„ç‰¹å¾µåç¨±
        base_feature = feature_name.split('_')[0]
        if base_feature in widget_map and base_feature not in inputs:
            inputs[base_feature] = widget_map[base_feature]()
    
    # å°‡é¡åˆ¥è¼¸å…¥è½‰æ›ç‚º one-hot encoding
    if 'enginetype' in inputs: inputs.update({f'enginetype_{et}': 1 if et == inputs['enginetype'] else 0 for et in df_raw['enginetype'].unique() if et != 'dohc'})
    if 'carbody' in inputs: inputs.update({f'carbody_{cb}': 1 if cb == inputs['carbody'] else 0 for cb in df_raw['carbody'].unique() if cb != 'convertible'})
    if 'cylindernumber' in inputs: inputs.update({f'cylindernumber_{cn}': 1 if cn == inputs['cylindernumber'] else 0 for cn in df_raw['cylindernumber'].unique() if cn != 'four'})
    if 'aspiration' in inputs: inputs.update({'aspiration_turbo': 1 if inputs['aspiration'] == 'turbo' else 0}) # drop_first='std'
    if 'enginelocation' in inputs: inputs.update({'enginelocation_rear': 1 if inputs['enginelocation'] == 'rear' else 0}) # drop_first='front'

    # å»ºç«‹ä¸€å€‹åŒ…å«æ‰€æœ‰å¯èƒ½ç‰¹å¾µçš„ DataFrame
    feature_df = pd.DataFrame([inputs])
    # ç¢ºä¿æ‰€æœ‰æ¨¡å‹éœ€è¦çš„æ¬„ä½éƒ½å­˜åœ¨
    for col in X_train.columns:
        if col not in feature_df.columns:
            feature_df[col] = 0
            
    return feature_df[selected_features], inputs # åŒæ™‚å›å‚³æ¨¡å‹è¼¸å…¥å’ŒåŸå§‹ä½¿ç”¨è€…è¼¸å…¥

# --- ä¸»é é¢ Tabs ---
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ” å–®ä¸€ç‰¹å¾µè¿´æ­¸åˆ†æ",
    "ğŸš€ ç‰¹å¾µé‡è¦æ€§èˆ‡è©•ä¼°æŒ‡æ¨™", 
    "ğŸ’° é æ¸¬è»Šåƒ¹",
    "ğŸ“ˆ æ•´é«”æ¨¡å‹é æ¸¬æ•ˆæœ",
])

with tab4: # ğŸ“ˆ æ•´é«”æ¨¡å‹é æ¸¬æ•ˆæœ
    st.subheader("å¤šå…ƒç·šæ€§è¿´æ­¸ï¼šå¯¦éš›åƒ¹æ ¼ vs. é æ¸¬åƒ¹æ ¼")
    st.write("é€™å¼µåœ–å±•ç¤ºäº†æˆ‘å€‘è¨“ç·´å‡ºçš„å¤šå…ƒç·šæ€§è¿´æ­¸æ¨¡å‹åœ¨æ¸¬è©¦è³‡æ–™ä¸Šçš„è¡¨ç¾ã€‚é»è¶Šé è¿‘ç´…è‰²çš„è™›ç·šï¼Œä»£è¡¨æ¨¡å‹çš„é æ¸¬è¶Šæº–ç¢ºã€‚")
    
    X_test, y_test = test_data
    X_test_selected = X_test[selected_features]
    y_pred_test = model.predict(X_test_selected)

    # ä½¿ç”¨ statsmodels ä¾†è¨ˆç®—é æ¸¬å€é–“
    X_test_const = sm.add_constant(X_test_selected)
    X_train_const = sm.add_constant(X_train[selected_features])
    ols_model = sm.OLS(y_train, X_train_const).fit()
    predictions_summary = ols_model.get_prediction(X_test_const).summary_frame(alpha=0.05)
    
    fig, ax = plt.subplots(figsize=(8, 6))

    # å†æ¬¡è¨­å®šå­—é«”ä»¥ç¢ºä¿åœ¨ Streamlit Cloud ä¸Šæ­£ç¢ºé¡¯ç¤º
    plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    
    # ç‚ºäº†æ­£ç¢ºç¹ªè£½å€é–“ï¼Œæˆ‘å€‘éœ€è¦æ ¹æ“šé æ¸¬å€¼å°æ‰€æœ‰ç›¸é—œè³‡æ–™é€²è¡Œæ’åº
    plot_data = predictions_summary.join(y_test).sort_values('mean')

    ax.scatter(y_pred_test, y_test, alpha=0.5, label="å¯¦éš›å€¼ vs. é æ¸¬å€¼")
    ax.fill_between(plot_data['mean'], plot_data['obs_ci_lower'], plot_data['obs_ci_upper'], color='lightblue', alpha=0.4, label='95% é æ¸¬å€é–“')
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label="å®Œç¾é æ¸¬ç·š")
    ax.set_xlabel("é æ¸¬åƒ¹æ ¼ (Predicted Price)")
    ax.set_ylabel("å¯¦éš›åƒ¹æ ¼ (Actual Price)")
    ax.set_title("æ•´é«”æ¨¡å‹é æ¸¬æ•ˆæœ")
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)
    
    st.info("""
    **åœ–è¡¨èªªæ˜ï¼š**
    - **è—è‰²æ•£ä½ˆé»**ï¼šä»£è¡¨æ¸¬è©¦è³‡æ–™ä¸­ï¼Œæ¯ä¸€è¼›è»Šçš„ã€Œé æ¸¬åƒ¹æ ¼ã€èˆ‡ã€Œå¯¦éš›åƒ¹æ ¼ã€çš„å°æ‡‰é—œä¿‚ã€‚
    - **ç´…è‰²è™›ç·š**ï¼šæ˜¯ã€Œå®Œç¾é æ¸¬ç·šã€ã€‚å¦‚æœæ¨¡å‹çš„é æ¸¬å®Œå…¨æº–ç¢ºï¼Œæ‰€æœ‰çš„é»éƒ½æœƒè½åœ¨é€™æ¢ç·šä¸Šã€‚
    - **æ·ºè—è‰²å€åŸŸ**ï¼šæ˜¯ **95% é æ¸¬å€é–“ (Prediction Interval)**ã€‚é€™è¡¨ç¤ºå°æ–¼ä»»ä½•ä¸€å€‹æ–°çš„é æ¸¬ï¼Œæˆ‘å€‘æœ‰ 95% çš„ä¿¡å¿ƒèªç‚ºå…¶ã€ŒçœŸå¯¦åƒ¹æ ¼ã€æœƒè½åœ¨è¿™ä¸ªå€é–“å…§ã€‚
    """, icon="ğŸ’¡")

with tab2: # ğŸš€ ç‰¹å¾µé‡è¦æ€§èˆ‡è©•ä¼°æŒ‡æ¨™
    st.subheader("æ¨¡å‹å¦‚ä½•ã€Œè‡ªå‹•ã€é¸æ“‡ç‰¹å¾µï¼Ÿ")
    st.write("æˆ‘å€‘çš„æ¨¡å‹ä½¿ç”¨äº†éæ­¸ç‰¹å¾µæ¶ˆé™¤ï¼ˆRFE, Recursive Feature Eliminationï¼‰æŠ€è¡“ï¼Œé€™æ˜¯ä¸€ç¨®è‡ªå‹•åŒ–çš„ç‰¹å¾µç¯©é¸æ–¹æ³•ã€‚å®ƒæœƒåè¦†å»ºç«‹æ¨¡å‹ï¼Œä¸¦ç§»é™¤æœ€ä¸é‡è¦çš„ç‰¹å¾µï¼Œç›´åˆ°å‰©ä¸‹æŒ‡å®šæ•¸é‡çš„æœ€ä½³ç‰¹å¾µçµ„åˆã€‚")
    
    st.subheader("ç‰¹å¾µé‡è¦æ€§æ’åº")
    st.write("ä¸‹åœ–é¡¯ç¤ºäº†æœ€çµ‚è¢«æ¨¡å‹é¸ä¸­çš„ç‰¹å¾µï¼Œä»¥åŠå®ƒå€‘å„è‡ªå°è»Šåƒ¹çš„å½±éŸ¿åŠ›ï¼ˆè¿´æ­¸ä¿‚æ•¸ï¼‰ã€‚")
    
    # ä½¿ç”¨åŸå§‹ä¿‚æ•¸ï¼ˆåŒ…å«æ­£è² è™Ÿï¼‰ä¾†ç¹ªåœ–
    importance_series = pd.Series(model.coef_, index=selected_features).sort_values(ascending=True)
    
    fig, ax = plt.subplots(figsize=(10, 8))
    ax.barh(importance_series.index, importance_series.values)
    ax.set_xlabel("è¿´æ­¸ä¿‚æ•¸å¤§å° (Coefficient Magnitude)")
    ax.set_title("ç‰¹å¾µé‡è¦æ€§æ’åº")
    ax.grid(True, linestyle='--', alpha=0.6)
    st.pyplot(fig)

    st.info("""
    **åœ–è¡¨è§£è®€ï¼š**
    - **æ­£å€¼ (é•·æ¢å‘å³)**ï¼šè¡¨ç¤ºè©²ç‰¹å¾µæ•¸å€¼è¶Šé«˜ï¼Œé æ¸¬çš„è»Šåƒ¹ä¹Ÿè¶Šé«˜ã€‚
    - **è² å€¼ (é•·æ¢å‘å·¦)**ï¼šè¡¨ç¤ºè©²ç‰¹å¾µæ•¸å€¼è¶Šé«˜ï¼Œé æ¸¬çš„è»Šåƒ¹åè€Œè¶Šä½ã€‚
    - **é•·æ¢é•·åº¦**ï¼šä»£è¡¨å½±éŸ¿ç¨‹åº¦çš„å¤§å°ã€‚
    """, icon="ğŸ’¡")
    
    st.subheader("æ¨¡å‹è¡¨ç¾æŒ‡æ¨™")
    r2, rmse = metrics
    m_col1, m_col2 = st.columns(2)
    m_col1.metric("RÂ² åˆ†æ•¸ (R-squared)", f"{r2:.4f}", help="æ¨¡å‹å°è³‡æ–™çš„è§£é‡‹èƒ½åŠ›ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½ã€‚")
    m_col2.metric("å‡æ–¹æ ¹èª¤å·® (RMSE)", f"${rmse:,.2f}", help="é æ¸¬å€¼èˆ‡å¯¦éš›å€¼çš„å¹³å‡å·®ç•°ï¼Œè¶Šå°è¶Šå¥½ã€‚")

with tab1: # ğŸ” å–®ä¸€ç‰¹å¾µè¿´æ­¸åˆ†æ
    st.subheader("å–®ç´”ç·šæ€§è¿´æ­¸ï¼šæ¢ç´¢å–®ä¸€ç‰¹å¾µèˆ‡åƒ¹æ ¼çš„é—œä¿‚")
    st.write("æ‚¨å¯ä»¥é¸æ“‡ä¸€å€‹æ•¸å€¼ç‰¹å¾µï¼Œè§€å¯Ÿå®ƒèˆ‡è»Šåƒ¹ä¹‹é–“çš„é—œä¿‚ä»¥åŠè¿´æ­¸è¶¨å‹¢ç·šã€‚")
    
    # è®“ä½¿ç”¨è€…é¸æ“‡è¦è¦–è¦ºåŒ–çš„ç‰¹å¾µ
    numeric_cols = df_raw.select_dtypes(include=np.number).columns.tolist()
    # æ’é™¤å·²çŸ¥çš„éç‰¹å¾µæ¬„ä½
    features_to_plot = [col for col in numeric_cols if col not in ['car_ID', 'symboling', 'price']]
    selected_feature_for_plot = st.selectbox("é¸æ“‡ä¸€å€‹ç‰¹å¾µé€²è¡Œåˆ†æï¼š", options=features_to_plot, index=features_to_plot.index('enginesize'))

    fig, ax = plt.subplots()
    sns.regplot(x=df_raw[selected_feature_for_plot], y=df_raw['price'], ax=ax, scatter_kws={'alpha':0.4})
    
    ax.set_title(f"{selected_feature_for_plot} vs. Price")
    ax.set_xlabel(selected_feature_for_plot)
    ax.set_ylabel("Price")
    ax.grid(True)
    st.pyplot(fig)
    
    st.info("""
    **åœ–è¡¨èªªæ˜ï¼š**
    - **ç°è‰²æ•£ä½ˆé»**ï¼šä»£è¡¨è³‡æ–™é›†ä¸­æ¯ä¸€è¼›è»Šçš„åŸå§‹æ•¸æ“šã€‚
    - **è—è‰²å¯¦ç·š**ï¼šæ˜¯åŸºæ–¼æ‰€æœ‰æ•¸æ“šè¨ˆç®—å‡ºçš„å–®ç´”ç·šæ€§è¿´æ­¸è¶¨å‹¢ç·šï¼Œè¡¨ç¤ºè©²ç‰¹å¾µèˆ‡åƒ¹æ ¼çš„å¤§è‡´é—œä¿‚ã€‚
    """, icon="ğŸ’¡")

with tab3: # ğŸ’° é æ¸¬è»Šåƒ¹
    st.subheader("èª¿æ•´è»Šè¼›åƒæ•¸ä»¥é€²è¡Œé æ¸¬")
    
    col1, col2 = st.columns(2)
    with col1:
        input_df, user_raw_inputs = user_input_features(importance_df, st)
    
    with col2:
        st.write("#### é æ¸¬çµæœ")
        # --- é¡¯ç¤ºé æ¸¬çµæœ ---
        prediction = model.predict(input_df)
        final_price = max(0, prediction[0]) # ç¢ºä¿åƒ¹æ ¼ä¸ç‚ºè² 

        st.metric(label="é æ¸¬è»Šåƒ¹", value=f"${final_price:,.2f}")

        if prediction[0] < 0:
            st.warning("æ³¨æ„ï¼šæ¨¡å‹é æ¸¬å‡ºè² åƒ¹æ ¼ã€‚é€™é€šå¸¸è¡¨ç¤ºæ‚¨é¸æ“‡çš„åƒæ•¸çµ„åˆåœ¨ç¾å¯¦å¸‚å ´ä¸­æ¥µç‚ºç½•è¦‹æˆ–ä¸å­˜åœ¨ã€‚é›–ç„¶è¼¸å…¥å€¼éƒ½åœ¨åˆç†ç¯„åœå…§ï¼Œä½†ç·šæ€§æ¨¡å‹å°æ–¼æ¥µç«¯çš„çµ„åˆå¯èƒ½æœƒç”¢ç”Ÿä¸åˆ‡å¯¦éš›çš„é æ¸¬ã€‚")
